Initializing program...
Preparing Dataset...
Optimizing hyperparameters...
Optimizing hyperparameters for ResNet18...
Testing combination (1/3): Learning Rate = 0.0001, Batch Size = 8, Optimizer = Adam
Epoch 1/2, Validation Loss: 0.1263
Epoch 2/2, Validation Loss: 0.0753
Testing combination (2/3): Learning Rate = 0.0001, Batch Size = 16, Optimizer = SGD
Epoch 1/2, Validation Loss: 1.5135
Epoch 2/2, Validation Loss: 1.3772
Testing combination (3/3): Learning Rate = 0.001, Batch Size = 16, Optimizer = SGD
Epoch 1/2, Validation Loss: 1.3022
Epoch 2/2, Validation Loss: 1.0121
Best params for ResNet18 (Val Loss = 0.0753099132174005): {'learning_rate': 0.0001, 'batch_size': 8, 'optimizer': <class 'torch.optim.adam.Adam'>}
Optimizing hyperparameters for VGG16...
Testing combination (1/3): Learning Rate = 0.001, Batch Size = 32, Optimizer = SGD
Epoch 1/2, Validation Loss: 1.1563
Epoch 2/2, Validation Loss: 0.9831
Testing combination (2/3): Learning Rate = 0.0001, Batch Size = 16, Optimizer = Adam
Epoch 1/2, Validation Loss: 0.1875
Epoch 2/2, Validation Loss: 0.3621
Testing combination (3/3): Learning Rate = 0.001, Batch Size = 16, Optimizer = SGD
Epoch 1/2, Validation Loss: 1.0145
Epoch 2/2, Validation Loss: 0.6938
Best params for VGG16 (Val Loss = 0.3620870957771937): {'learning_rate': 0.0001, 'batch_size': 16, 'optimizer': <class 'torch.optim.adam.Adam'>}
Optimizing hyperparameters for InceptionV3...
Testing combination (1/3): Learning Rate = 0.001, Batch Size = 32, Optimizer = Adam
Epoch 1/2, Validation Loss: 1.8908
Epoch 2/2, Validation Loss: 3.3290
Testing combination (2/3): Learning Rate = 0.01, Batch Size = 8, Optimizer = SGD
Epoch 1/2, Validation Loss: 0.2923
Epoch 2/2, Validation Loss: 0.1287
Testing combination (3/3): Learning Rate = 0.001, Batch Size = 32, Optimizer = SGD
Epoch 1/2, Validation Loss: 1.2344
Epoch 2/2, Validation Loss: 1.2227
Best params for InceptionV3 (Val Loss = 0.1286665623386701): {'learning_rate': 0.01, 'batch_size': 8, 'optimizer': <class 'torch.optim.sgd.SGD'>}
Optimizing hyperparameters for DenseNet...
Testing combination (1/3): Learning Rate = 0.001, Batch Size = 16, Optimizer = Adam
Epoch 1/2, Validation Loss: 2.1337
Epoch 2/2, Validation Loss: 1.7071
Testing combination (2/3): Learning Rate = 0.001, Batch Size = 32, Optimizer = Adam
Epoch 1/2, Validation Loss: 1.9506
Epoch 2/2, Validation Loss: 1.1648
Testing combination (3/3): Learning Rate = 0.0001, Batch Size = 8, Optimizer = Adam
Epoch 1/2, Validation Loss: 0.1183
Epoch 2/2, Validation Loss: 0.0784
Best params for DenseNet (Val Loss = 0.07841487104694049): {'learning_rate': 0.0001, 'batch_size': 8, 'optimizer': <class 'torch.optim.adam.Adam'>}
Optimizing hyperparameters for MobileNetV2...
Testing combination (1/3): Learning Rate = 0.0001, Batch Size = 8, Optimizer = SGD
Epoch 1/2, Validation Loss: 1.3104
Epoch 2/2, Validation Loss: 1.2794
Testing combination (2/3): Learning Rate = 0.01, Batch Size = 8, Optimizer = SGD
Epoch 1/2, Validation Loss: 0.2078
Epoch 2/2, Validation Loss: 0.1480
Testing combination (3/3): Learning Rate = 0.001, Batch Size = 16, Optimizer = SGD
Epoch 1/2, Validation Loss: 1.2352
Epoch 2/2, Validation Loss: 1.1208
Best params for MobileNetV2 (Val Loss = 0.14799448164800802): {'learning_rate': 0.01, 'batch_size': 8, 'optimizer': <class 'torch.optim.sgd.SGD'>}
Initializing models...
Initializing ResNet18...
Initializing VGG16...
Initializing InceptionV3...
Initializing DenseNet...
Initializing MobileNetV2...
Training models...
Training ResNet18... (Hyper Params: Learning Rate = 0.0001, Batch Size = 8, Optimizer = Adam)
Epoch 1/4, Train Loss: 1.4714, Val Loss: 1.3852
Epoch 2/4, Train Loss: 1.3326, Val Loss: 1.3137
Epoch 3/4, Train Loss: 1.2584, Val Loss: 1.2008
Epoch 4/4, Train Loss: 1.1952, Val Loss: 1.1469
Time spent: 0 min 48 sec of 120 min allowed.
Training VGG16... (Hyper Params: Learning Rate = 0.0001, Batch Size = 16, Optimizer = Adam)
Epoch 1/4, Train Loss: 1.3867, Val Loss: 1.2348
Epoch 2/4, Train Loss: 1.1343, Val Loss: 1.0242
Epoch 3/4, Train Loss: 0.9471, Val Loss: 0.8629
Epoch 4/4, Train Loss: 0.7875, Val Loss: 0.7327
Time spent: 4 min 26 sec of 120 min allowed.
Training InceptionV3... (Hyper Params: Learning Rate = 0.01, Batch Size = 8, Optimizer = SGD)
Epoch 1/4, Train Loss: 1.1457, Val Loss: 0.9624
Epoch 2/4, Train Loss: 0.7322, Val Loss: 0.4875
Epoch 3/4, Train Loss: 0.5182, Val Loss: 0.3611
Epoch 4/4, Train Loss: 0.4046, Val Loss: 0.2475
Time spent: 1 min 42 sec of 120 min allowed.
Training DenseNet... (Hyper Params: Learning Rate = 0.0001, Batch Size = 8, Optimizer = Adam)
Epoch 1/4, Train Loss: 1.3672, Val Loss: 1.2234
Epoch 2/4, Train Loss: 1.2731, Val Loss: 1.1467
Epoch 3/4, Train Loss: 1.1824, Val Loss: 1.0656
Epoch 4/4, Train Loss: 1.0905, Val Loss: 0.9828
Time spent: 2 min 35 sec of 120 min allowed.
Training MobileNetV2... (Hyper Params: Learning Rate = 0.01, Batch Size = 8, Optimizer = SGD)
Epoch 1/4, Train Loss: 1.2024, Val Loss: 0.6690
Epoch 2/4, Train Loss: 0.6920, Val Loss: 0.4365
Epoch 3/4, Train Loss: 0.4344, Val Loss: 0.2564
Epoch 4/4, Train Loss: 0.4309, Val Loss: 0.2313
Time spent: 1 min 4 sec of 120 min allowed.
Evaluating models...
Evaluating ResNet18 on Test Data...
Confusion Matrix:
[[17  0  1  0]
 [ 0 19  0  1]
 [ 0  9  8  1]
 [ 0  3  0 21]]
Accuracy: 0.8125
Precision: 0.8521
Recall: 0.8125
F1-Score: 0.8063
Evaluating VGG16 on Test Data...
Confusion Matrix:
[[18  0  0  0]
 [ 0 19  1  0]
 [ 0  3 15  0]
 [ 0  0  0 24]]
Accuracy: 0.9500
Precision: 0.9518
Recall: 0.9500
F1-Score: 0.9497
Evaluating InceptionV3 on Test Data...
Confusion Matrix:
[[18  0  0  0]
 [ 0 19  1  0]
 [ 0  0 18  0]
 [ 0  0  0 24]]
Accuracy: 0.9875
Precision: 0.9882
Recall: 0.9875
F1-Score: 0.9875
Evaluating DenseNet on Test Data...
Confusion Matrix:
[[18  0  0  0]
 [ 0 19  1  0]
 [ 0  4 12  2]
 [ 0  0  1 23]]
Accuracy: 0.9000
Precision: 0.9004
Recall: 0.9000
F1-Score: 0.8963
Evaluating MobileNetV2 on Test Data...
Confusion Matrix:
[[18  0  0  0]
 [ 0 20  0  0]
 [ 0  0 16  2]
 [ 0  0  0 24]]
Accuracy: 0.9750
Precision: 0.9769
Recall: 0.9750
F1-Score: 0.9748
